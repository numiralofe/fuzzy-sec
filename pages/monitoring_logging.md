# Monitoring and Logging
[back](../README.md)


**Monitoring**

For monitoring we could use an hybrid approach 

* Prometheus scraping data from containers and applications that we can use this data to trigger events like autoscaling actions or alerts and notifications.

* Taking in consideration that we also have the elk stack available to gather and collect logs we could use metricbeat to collect data about system info, running containers, applications metrics and persist this data over time on the elastic search cluster.

**Deploying Prometheus**

We would deploy prometheus service as a data source that scraps data from all the containers and raw payloads that were executed or are in execution by the cluster, in order to achieve this we would implement 2 simple solutions:

by using nomad to orchestrate all applicational deployments we can take advantage of nomad agent metrics built in functionality since at this level we have available, metrics from all running containers and running raw payloads, in order to gather all metrics in a single location we need to deploy Prometheus in the cluster itself so that from there we can start scraping and collecting metrics from running applications.

First for all this to happen we need to enable telemetry on the Nomad nodes and configure Prometheus to use Consul for service discovery. 

To enable telemetry on the nomad cluster:

````
telemetry {
  collection_interval = "1s"
  disable_hostname = true
  prometheus_metrics = true
  publish_allocation_metrics = true
  publish_node_metrics = true
}
````

The deploy prometheus on the nomad cluster to gather data from containers/services/raw_payloads that are registered in consul.

````
    task "prometheus" {
      template {
        change_mode = "noop"
        destination = "local/prometheus.yml"
        data = <<EOH
---
global:
  scrape_interval:     5s
  evaluation_interval: 5s

scrape_configs:

  - job_name: 'nomad_metrics'

    consul_sd_configs:
    - server: '{{ env "NOMAD_IP_prometheus_ui" }}:8500'
      services: ['nomad-client', 'nomad']

    relabel_configs:
    - source_labels: ['__meta_consul_tags']
      regex: '(.*)http(.*)'
      action: keep

    scrape_interval: 5s
    metrics_path: /v1/metrics
    params:
      format: ['prometheus']
EOH
      }
````

Once those steps are completed, prometheus should be scraping nomad agents api and collecting data from the running applications, as so we need now to deploy grafana and use prometheus as its data source so that then we can setup dashboards about metric's collected from prometheus, like global CPU usage per service, number of instances running, network usage, etc etc also some additional configuration can be added on grafana to trigger alerts based on pre defined thresholds.

Grafana can be deployed inside the cluster as following and we would need a volume in order to persist monitoring configurations and graphs data:

```
        group "nomadDashboard" {
            task "grafana" {
            driver = "docker"
            config {
                image = "grafana/grafana"
                privileged = true
                network_mode = "host"

        mounts = [
          {
            target = "/var/lib/grafana"
            source = "grafana-volume"
            readonly = false
            volume_options {
              driver_config {
                name = "local"
              }
            }
```            

As mentioned initially, because we are using the elk stack we could also take advantage of metricbeat, to collect further info about the nodes, applications and other resources of the environment so that we can persist this data over time. 
We should deploy it as a system job so that its deployed on all nodes of the existing clusters, to achieve that we could use this approach:

```
job "metricbeat" {
	type = "system"
	datacenters = ["eu-dc1,us-dc1"]
	group "metricbeat" {
		task "metricbeat" {
				driver = "docker"
				config {
						image = "elastic/metricbeat:7.3.2"
						command = "-strict.perms=false"
						force_pull = true
						logging {
							type = "json-file"
						}

```


**Logging**

As for logging, it consists on a central elastic search cluster that receives all logs from all running applications regardless of their location and workload type and a kibana dashboard so that we can analyze these logs. 

The elastic/kibana combo/setup is common and i am not going to detail it much, just would like to add my ideas to solve the log shipping problem from multiple locations, for that we could use the following option:


* deploy one filebeat agent per node of the cluster so that it harvest all logs generated by the running containers or raw executions and ships them to a central location, the filebeat agent would be deployed as a container using a nomad job with the following details:

````
				config {
						image = "elastic/filebeat:7.3.0"
						command = "-strict.perms=false"
						force_pull = true
						volumes = [
							"filebeat_data:/usr/share/filebeat/data:rw",
							"/var/run/docker.sock:/var/run/docker.sock:ro",
							"/var/lib/docker/containers:/var/lib/docker/containers:ro"
						]

						logging {
							type = "json-file"
						}
          env {
            SERVER_NAME="filebeat"
            ELASTICSEARCH_HOSTS="https:/elasticsearch-logcluster:9200"
          }            
				}
````        

2. For apps running in containers we need to set their log output to stdout and at the hcl stanza  define the tags that filebeat will scrap from the docker daemon in order to ship them to the central elastic cluster.

```
				config {
						image = "myregistry.com/myapp:2.0.0"
						force_pull = true
						logging {
							type = "json-file"
						}
						labels {
                           image_name = "myapp"
                           image_version = "2.0.0"
                           my_other_label = "bla bla"
                        }
        }              
 ````

3. For raw payloads/executions we need to define on the filebeat yaml configuration file folders where to harvest logs from and also set properties and tags based on that. 

```
filebeat.prospectors:
- input_type: log
  fields:
    type: syslog
  paths:
    - /var/log/myapp/*
    - /alloc/logs/*

name: "myapp"
tags: "myapp tag"
```
